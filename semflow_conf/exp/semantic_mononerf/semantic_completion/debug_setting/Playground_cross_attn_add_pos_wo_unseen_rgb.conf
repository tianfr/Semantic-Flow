# DTU config
include required("../../../../default_mv.conf")
# train {
#     num_epoch_repeats = 32
#     vis_interval = 200
# }
# renderer {
#     white_bkgd = False
# }
# data {
#     format = dvr_dtu
#     # ban_views = [3, 4, 5, 6, 7, 16, 17, 18, 19, 20, 21, 36, 37, 38, 39]
# }
scene = Playground
N_samples = 64
N_rays = 1024
model {
    # ndc coordinate
    use_ndc = True
    use_semantic_labels = True
    semantic_class_num = 30
    use_ray_attention = True
    completion_mode = True

    ray_attention{
        intra_attn_head = 4
        cross_attn_head = 4
        N_samples = ${N_samples}
        d_hidden = 64
        add_pos_embedding = True
        intra_attn = False
    }

    mlp_static {
        pixelnerf_mode = True
        origin_pipeline = False
        use_semantic_labels = False

    }

    mlp_dynamic {
        pixelnerf_mode = True
        feature_fuse_mode = "addition"
        use_viewdirsDyn = False
        flow_mode = "discrete"
        use_adjoint = False
        d_hidden = 128
        discrete_steps = 2
        origin_pipeline = False
        n_global_blocks = 2
        n_blocks = 3
        use_temporal_feature = True
        use_semantic_labels = True

    }

    encoder_2d {
        type = resnet18
        normalize = Ture
    }

    encoder {
        type = slowonly
        config_path = "mmaction_configs/recognition/slowonly/slowonly_imagenet_pretrained_r50_8x8x1_150e_kinetics400_rgb.py"
        pretrained = True
        pretrained_path = "checkpoints/slowonly_imagenet_pretrained_r50_8x8x1_150e_kinetics400_rgb_20200912-3f9ce182.pth"
        num_layers = [0, 1, 2]
        use_encoder_2d = True
    }
}

info {
    add_features = True
    basedir = "./logs/semantic_mononerf/completion/debug_setting/semanticflow/after_debug"
    # basedir = "./logs/debug/"
    expname = 50_${scene}_cross_attn_add_pos_use_all_static_frames_use_abs_pos_wo_unseen_rgb
    ft_S = True
    # ft_path_S = "/mnt/cache/tianfengrui/NeRF_series/SeDyODENeRF/logs/Dyfeature_ablation/1gpuspretrain_Balloon2_freeze_2encoder_wo_depth_blending_no_ndc/Pretrained_S.tar"
    # use ndc
    # ft_path_S = /data/tianfr/NeRF_series/SemanticFlow/logs/semantic_mononerf/completion/debug_setting/semanticflow/1gpusgap_Balloon1_cross_attn_add_pos_use_all_static_frames/Pretrained_S.tar
    ft_path_S = None
    dataset_file_lists = [data_semantic/${scene}]
    random_seed = 42
    freeze_enc = True
    N_rand = ${N_rays}
    blending_thickness = 0.03
    no_ndc = False
    use_lambda_decay = False
    use_depth_blending_loss = True
    use_static_flow_loss = True
    static_flow_loss_lambda = 0.5
    use_mask_flow_loss = True
    mask_flow_loss_lambda = 0.01
    decay_iteration = 0
    freeze_BN = False
    use_clip_grad_norm = True
    w_semantic_label_frames = [0,1,2,9,10,11]
    testset_all = True
    use_semantic_consistency = True
    semantic_loss_lambda = 0.08
    semantic_loss_lambda_full = 0.16
    semantic_loss_lambda_d = 0.08
    lrate_decay = 80000
    use_all_static_frames = True
    wo_unseen_rgb = True
    # slow_loss_lambda = 0.1
    # flow_loss_lambda = 0.2
}