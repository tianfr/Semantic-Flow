# Single-view only base model
# (Not used in experiments; resnet_fine_mv.conf inherits)
model {
    # Condition on local encoder
    use_encoder = True

    # ndc coordinate
    use_ndc = True

    # Condition also on a global encoder?
    use_global_encoder = False
    
    # Use xyz input instead of just z
    # (didn't ablate)
    use_xyz = True
    
    # Canonical space xyz (default view space)
    canon_xyz = False

    # Positional encoding
    use_code = True
    code {
        num_freqs = 6
        freq_factor = 1.5
        include_input = True
    }

    # View directions
    use_viewdirs = True
    # Apply pos. enc. to viewdirs?
    use_code_viewdirs = False

    # MLP architecture
    mlp_static {
        type = resnet_static  # Can change to mlp
        n_blocks = 5
        d_hidden = 256
    }
    mlp_dynamic {
        type = resnet
        n_blocks = 5
        d_hidden = 256
        use_viewdirsDyn = False
        use_sf_nonlinear = False
        n_global_blocks = 0
        n_blocks = 5
        use_temporal_feature=False
    }

    # Encoder architecture
    encoder {
        type = slowonly
        config_path = "mmaction_configs/recognition/slowonly/slowonly_imagenet_pretrained_r50_8x8x1_150e_kinetics400_rgb.py"
        pretrained = True
        pretrained_path = "checkpoints/slowonly_imagenet_pretrained_r50_8x8x1_150e_kinetics400_rgb_20200912-3f9ce182.pth"
        num_layers = 4
        use_encoder_2d = True
    }

    # Encoder2D architecture
    encoder_2d {
        type = resnet18
        normalize = True
    }
}
renderer {
    n_coarse = 64
    n_fine = 32
    # Try using expected depth sample
    n_fine_depth = 16
    # Noise to add to depth sample
    depth_std = 0.01
    # Decay schedule, not used
    sched = []
    # White background color (false : black)
    white_bkgd = True
}
loss {
    # RGB losses coarse/fine
    rgb {
        use_l1 = False
    }
    rgb_fine {
        use_l1 = False
    }
    # Alpha regularization (disabled in final version)
    alpha {
        # lambda_alpha = 0.0001
        lambda_alpha = 0.0
        clamp_alpha = 100
        init_epoch = 5
    }
    # Coarse/fine weighting (nerf = equal)
    lambda_coarse = 1.0  # loss = lambda_coarse * loss_coarse + loss_fine
    lambda_fine = 1.0  # loss = lambda_coarse * loss_coarse + loss_fine
}
train {
    # Training 
    print_interval = 2
    save_interval = 50
    vis_interval = 100
    eval_interval = 50

    # Accumulating gradients. Not really recommended.
    # 1 = disable
    accu_grad = 1

    # Number of times to repeat dataset per 'epoch'
    # Useful if dataset is extremely small, like DTU
    num_epoch_repeats = 1
}

info {
    add_features = True
    basedir = "./undefined/"
    expname = "pretrain_Balloon2_freeze_2encoder_wo_depth_blending_256channel_useviewdir_SDresnet"
    ft_S = True
    ft_path_S = None
    dataset_file_lists = [data/Balloon2]
    random_seed = 42
    freeze_enc = True
    N_rand = 1024
    no_ndc = False
    chunk = 16384
    blending_thickness = 0.06
    evaldir = "multiview"
    slow_loss_lambda = 0.01
    flow_loss_lambda = 0.02

}